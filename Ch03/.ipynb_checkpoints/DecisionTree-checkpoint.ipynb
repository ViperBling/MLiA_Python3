{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树\n",
    "> 优点：计算复杂度不高，输出结果易于理解，对中间值缺失不敏感，可以处理不相关特征数据。<br>\n",
    "> 缺点：可能会产生过拟合问题。<br>\n",
    "> 适用数据类型：数值型和标称型。\n",
    "\n",
    "决策树的一般流程\n",
    "> 1. 收集数据<br>\n",
    "> 2. 准备数据：树构造算法只适用于标称型数据，所以数值型数据需要离散化。<br>\n",
    "> 3. 分析数据：可以使用任何方法，构造树完成后，应该检查图形是否符合预期。<br>\n",
    "> 4. 训练算法：构造树的数据结构。<br>\n",
    "> 5. 测试算法：使用验证集计算错误率。<br>\n",
    "> 6. 使用算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 信息熵\n",
    "信息熵：$$H=-\\sum_{i=1}^{n}p(x_i)\\log_2{p}(x_i)$$\n",
    "计算信息熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import operator\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcShannonEnt(dataSet):\n",
    "    \"\"\"Calculate Shannon entropy\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    shannonEnt\n",
    "    \"\"\"\n",
    "    \n",
    "    # 将数据转化为numpy数组\n",
    "    dataSet = np.array(dataSet)\n",
    "    numEntries = dataSet.shape[0]\n",
    "    \n",
    "    # 使用unique方法获得不同的标签\n",
    "    labelCounts = np.unique(dataSet[:, -1])\n",
    "    \n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        # 计算dataSet中所有值为key的样本个数\n",
    "        numKey = np.sum(dataSet[:, -1] == key)\n",
    "        prob = numKey / numEntries\n",
    "        shannonEnt -= prob * log(prob, 2)\n",
    "        \n",
    "    \n",
    "#     # 计算数据集长度\n",
    "#     numEntries = len(dataSet)\n",
    "    \n",
    "#     # 计算分类标签的出现次数\n",
    "#     labelCounts = {}\n",
    "#     for featVec in dataSet:\n",
    "        \n",
    "#         # 获取当前条目的标签\n",
    "#         currentLabel = featVec[-1]\n",
    "#         # 为所有可能的分类创建键值，如果当前键值不存在，则加入到字典。\n",
    "#         # 每个键值记录了当前类别出现的次数\n",
    "#         if currentLabel not in labelCounts.keys():\n",
    "#             labelCounts[currentLabel] = 0\n",
    "#         labelCounts[currentLabel] += 1\n",
    "        \n",
    "#         # 对于label的占比，求出当前label的信息熵\n",
    "#         shannonEnt = 0.0\n",
    "#         for key in labelCounts:\n",
    "#             prob = float(labelCounts[key]) / numEntries\n",
    "#             shannonEnt -= prob * log(prob, 2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试信息熵计算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 划分数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitDataSet的功能是当我们按照某个特征划分数据集时，将所有符合要求的样本抽取出来。并且将特征从样本中剔除，从而可以进行下一步的特征提取。提取dataSet中所有值为value的第index个特征值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, index, value):\n",
    "    \"\"\"Split DataSet with index.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    dataSet : Data for split.\n",
    "    index : Feature index of dataSet.\n",
    "    value : Feature value.\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    index\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "#     dataSet = np.array(dataSet)\n",
    "    \n",
    "#     valueArr = dataSet[dataSet[:, index] == str(value)]\n",
    "#     retDataSet = np.delete(valueArr, index, axis=1)\n",
    "    \n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        \n",
    "        if featVec[index] == value:\n",
    "            reducedFeatVec = featVec[:index]\n",
    "            \n",
    "            reducedFeatVec.extend(featVec[index+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "            \n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'no'], [1, 'no']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitDataSet(myDat, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面将遍历整个数据集，循环计算信息熵和splitDataSet函数，找到最好的特征划分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    ---------\n",
    "    bestFeature : The best feature of dataset spliting.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # 这里dataSet为二维数组，并不是numpy数组。\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    \n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain, bestFeature = 0.0, -1\n",
    "    \n",
    "    # 遍历所有的特征。\n",
    "    for i in range(numFeatures):\n",
    "        # 获取每个输入的第i+1个特征\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        # 这一步去除重复项后就得到了特征所有可能的值。\n",
    "        uniqueVals = set(featList)\n",
    "        \n",
    "        newEntropy = 0.0\n",
    "        \n",
    "        for value in uniqueVals:\n",
    "            # 获取第i个特征中值为value的子集\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            \n",
    "            prob = len(subDataSet) / float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "            \n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    \n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chooseBestFeatureToSplit(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 递归构建决策树\n",
    "递归结束的条件：程序遍历完所有划分数据集的属性，或者分支下的所有实例都具有相同的分类，如果所有实例具有相同的分类则得到一个叶子结点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorityCnt(classList):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    -----------\n",
    "    classList : label\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    bestFeature : best feature list\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "#     classCount = {}\n",
    "#     for vote in classList:\n",
    "#         if vote not in classCount.keys():\n",
    "#             classCount[vote] = 0\n",
    "#         classCount[vote] += 1\n",
    "        \n",
    "#     sortedClassCount = sorted(classCount.items(), key = operator.itemgetter(1), reverse=True)\n",
    "#     return sortedClassCount[0][0]\n",
    "    \n",
    "    majorLabel = collections.Counter(classList).most_common(1)[0]\n",
    "    return majorLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet, labels):\n",
    "    classList = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "SVM的优缺点：\n",
    "> 优点：泛化错误率低，计算开销不大，结果易解释。\n",
    "> 缺点：对参数调节和核函数的选择较为敏感，原始分类器不做修改仅适用于二分类问题。\n",
    "> 适用数据类型：数值型和标称型。\n",
    "\n",
    "SVM的一般流程：\n",
    "> 1. 收集数据:可以使用任意方法。\n",
    "> 2. 准备数据:需要数值型数据。\n",
    "> 3. 分析数据:有助于可视化分隔超平面。\n",
    "> 4. 训练算法:SVM的大部分时间都源自训练,该过程主要实现两个参数的调优。\n",
    "> 5. 测试算法:十分简单的计算过程就可以实现。\n",
    "> 6. 使用算法:几乎所有分类问题都可以使用SVM,值得一提的是,SVM本身是一个二类分类器,对多类问题应用SVM需要对代码做一些修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用拉格朗日乘子法可以得到SVM最优化问题的对偶问题如下：\n",
    "$$\n",
    "\\begin{align}\n",
    "\\max_{\\alpha}&\\sum_{i=1}^{m}\\alpha_i-\\frac12\\sum_{i=1}^m\\sum_{j=1}^m\\alpha_i\\alpha_jy_iy_j\\boldsymbol{x}_i^T\\boldsymbol{x}_j \\tag{1} \\\\\n",
    "s.t. &\\sum_{i=1}^m\\alpha_iy_i=0 \\\\\n",
    "&\\alpha_i\\geq0, i=1,2,...,m.\n",
    "\\end{align}\n",
    "$$\n",
    "我们的目标就是求解（1）式在约束条件下的最优解。这是一个二次规划问题。<br>\n",
    "SMO的基本思路是先固定$\\alpha_i$之外的所有参数，然后求$\\alpha_i$上的极值。由于存在约束${\\sum}_{i=1}^m\\alpha_iy_i=0$，若固定$\\alpha_i$之外的其他变量，则$\\alpha_i$可以由其他变量导出。于是，SMO每次选择两个变量$\\alpha_i$和$\\alpha_j$，并固定其他参数，这样在初始化后，SMO不断执行以下两个步骤直至收敛：\n",
    "> 1. 选取一对需要更新的变量$\\alpha_i$和$\\alpha_j$；\n",
    "> 2. 固定$\\alpha_i$和$\\alpha_j$以外的参数，求解（1）式获得更新后的$\\alpha_i$和$\\alpha_j$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 使用简化版SMO处理小规模数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataMat.append(float(lineArr[0]), float(lineArr[1]))\n",
    "        labelMat.append(float(lineArr[2]))\n",
    "    return dataMat, labelMat\n",
    "\n",
    "def selectJrand(i, m):\n",
    "    \"\"\"随机选择一个整数\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    i : 第一个alpha的下标\n",
    "    m : 所有alpha的数目\n",
    "    \n",
    "    Returns\n",
    "    ------------\n",
    "    j : 一个不为i的随机数，在0～m之间\n",
    "    \"\"\"\n",
    "    j = i\n",
    "    while (j == i):\n",
    "        j = int(np.random.uniform(0, m))\n",
    "    return j\n",
    "\n",
    "def clipAlpha(aj, H, L):\n",
    "    \"\"\"调整aj的值，使L<=aj<=H\"\"\"\n",
    "    \n",
    "    if aj > H:\n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return aj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smoSimple，简化版的SMO算法函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoSimple(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    \"\"\"SMO算法简化版\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    dataMatIn : 输入数据集\n",
    "    classLabel : 类别标签\n",
    "    C : 松弛变量，允许少量数据点被误分类，控制最大化间隔。\n",
    "    toler : 容错率\n",
    "    maxIter : 退出最大的循环次数\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    b : 模型的截距值\n",
    "    alphas : 拉格朗日乘子\n",
    "    \"\"\"\n",
    "    \n",
    "    dataMatrix = np.mat(dataMatIn); labelMat = np.mat(classLabels).T\n",
    "    # 参数初始化\n",
    "    b = 0; m, n = dataMatrix.shape\n",
    "    alphas = np.mat(np.zeros((m, 1)))\n",
    "    iter = 0\n",
    "    while (iter < maxIter):\n",
    "        # alphaPairsChanged记录alpha是否已经进行优化\n",
    "        alphaPairsChanged = 0\n",
    "        for i in range(m):\n",
    "            # 预测的输出，y = w^Tx[i] + b;其中w = Σ(1~n) a[n]*lable[n]*x[n]\n",
    "            fXi = float(np.multiply(alphas, labelMat).T * (dataMatrix * dataMatrix[i, :])) + b\n",
    "            # Ei为误差\n",
    "            Ei = fXi - float(labelMat[i])\n",
    "            \n",
    "            # KKT条件\n",
    "            # 0<=alphas[i]<=C，但由于0和C是边界值，我们无法进行优化，因为需要增加一个alphas和降低一个alphas。\n",
    "            # 表示发生错误的概率：labelMat[i]*Ei 如果超出了 toler， 才需要优化。\n",
    "            if ((labelMat[i] * Ei < -toler) and (alphas[i] < C)) or \\\n",
    "                ((labelMat[i] * Ei > toler) and (alphas[i] > 0)):\n",
    "                # 满足条件，选取非i的点进行优化比较\n",
    "                j = selectJrand(i, m)\n",
    "                # 预测j的结果\n",
    "                fXj = float(np.multiply(alphas, labelMat).T * \\\n",
    "                      (dataMatrix * dataMatrix[j, :].T)) + b\n",
    "                Ej = fXj - float(labelMat[j])\n",
    "                alphaIold = alphas[i].copy()\n",
    "                alphaJold = alphas[j].copy()\n",
    "                \n",
    "                # L和H用于将alphas[j]调整到0～C之间，L == H则不作改变\n",
    "                # labelMat[i] != labelMat[j]表示两个点在异侧，则相减，否则相加\n",
    "                if (labelMat[i] != labelMat[j]):\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                if L == H: print(\"L == H\"); continue\n",
    "                    \n",
    "                \n",
    "                eta = 2.0 * dataMatrix[i, :] * dataMatrix[j, :].T - \\\n",
    "                      dataMatrix[i, :] * dataMatrix[i, :].T - \\\n",
    "                      dataMatrix[j, :] * dataMatrix[j, :].T\n",
    "                \n",
    "                if eta >= 0: print(\"eta >= 0\"); continue\n",
    "                alphas[j] -= labelMat[j] * (Ei - Ej) / eta\n",
    "                alphas[j] = clipAlpha(alphas[j], H, L)\n",
    "                if (abs(alphas[j] - alphaJold) < 0.00001):\n",
    "                    print(\"j not moving enough\"); continue\n",
    "                alphas[i] += labelMat[j] * labelMat[i] * (alphaJold - alphas[j])\n",
    "                b1 = b - Ei - labelMat[i] * (alphas[i] - alphaIold) * \\\n",
    "                     dataMatrix[i, :] * dataMatrix[i, :].T - \\\n",
    "                     labelMat[j] * (alphas[j] - alphaJold) * \\\n",
    "                     dataMatrix[i, :] * dataMatrix[j, :].T\n",
    "                b2 = b - Ej - labelMat[i] * (alphas[i] - alphaIold) * \\\n",
    "                     dataMatrix[i, :] * dataMatrix[j, :].T - \\\n",
    "                     labelMat[j] * (alphas[j] - alphaJold) * \\\n",
    "                     dataMatrix[j, :] * dataMatrix[j, :].T\n",
    "                if (0 < alphas[i]) and (C > alphas[i]): b = b1\n",
    "                elif (0 < alphas[j]) and (C > alphas[j]): b = b2\n",
    "                else: b = (b1 + b2) / 2.0\n",
    "                alphaPairsChanged += 1\n",
    "                print(\"iter: %d  i: %d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "        if (alphaPairsChanged == 0): iter += 1\n",
    "        else: iter = 0\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return b, alphas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
